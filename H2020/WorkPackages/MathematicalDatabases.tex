\addtocounter{wpno}{1}
\begin{Workpackage}{\thewpno}
\wplabel{wp:x}
\WPTitle{\wpname{\thewpno}}
\WPStart{Month 1}
\WPParticipant{ZH}{1}

\begin{WPObjectives}
  The objectives of \theWP{} is to design interfaces that can be used
  for a wide range of mathematical data, facilities for accepting
  contributions while tracking provenance and credit, and definition of standard
  metadata allowing for interoperability, database discovery, 
  versioning allowing stable references, and easy recomputation.
  
%  Participants: Warwick, Zurich, Logilab (SME in Paris)
\end{WPObjectives}


\begin{WPDescription}
Mathematics is the only science that has not yet benefited massively from the systematic interchange of data. Many mathematical databases now exist, but their internal structure does not surface the richness of the interconnections between the objects that are studied. This prevents the formulation of new conjectures, the testing of new hypotheses, and generally an exploratory approach to mathematical data. The past has shown that this approach could be fruitful: 
\begin{itemize}
\item both the Riemann Hypothesis and the Birch and Swinnerton Dyer conjectures resulted from computations, and now stand among the seven Clay Millenium Problems;
\item the Monstrous Moonshine conjecture finds its origin in a numerical co\"incidence between dimensions of representations of the Monster group and coefficients of the $j$-function, and its conclusion eventually led to Borcherds' Fields medal.
\end{itemize}

Existing tools are not suitable for this hypothesis generation across mathematical subdisciplines: both sides are usually studied by different communities, and the interconnections have themselves such complexity that they typically become the object of study of yet another group of mathematicians. This explains the need for infrastructure that could be used uniformly over wide ranges of mathematics, certainly poses additional challenges compared to existing solutions, but also allows for potentially groundbreaking improvements. At the same time, some issues are less prevalent in mathematics, for instance tied to "veracity": most often the data results from deterministic computations implemented via exact and verified algorithms. 

We propose in this work package to design and build an infrastructure that would make it easy for either isolated mathematicians or a distributed collaboration to manage mathematical data. This work would provide part of the backend to Work Packages \TODO{work package on interfaces, and???}, and would draw on previous work with the LMFDB and FindStat (which will be looked at as prototypes for our purposes). Requirements should be as minimal as possible (depending on the individual's goals), and in particular would not require any background in databases to contribute new data or perform queries. 
\end{WPDescription}

\begin{task}{Survey of existing databases}
\label{task:data_assessment}
All the systems considered in this proposal (\GAP, \Sage, \Pari, \Singular) include data as part of their regular distribution. In this task, we will survey existing databases, the technology used to implement them, how they were linked to the rest of the existing infrastructure and the functionalities offered. We will also select additional external data and projects to add to this effort, aiming to maximise the impact of our work. 
\end{task}

\begin{task}{Design of new infrastructure, formulation of requirements}
\label{task:data_design}
Ontologies are the canonical method used to implement databases that require significant data interchange. However, because of extreme reification in mathematics, this is not entirely suitable for our goals. We will design a new infrastructure for \TheProject, drawing on existing emerging standards . 


\begin{itemize}
\item Implementation MMT - > Logilab
\item Math flexiformalisation, conversion of existing data
\item Search functionality
\item Memoization
\end{itemize}

  \begin{itemize}
  \item Polytopes in Polymake
  \item graphs, graph properties
  \item existing in LMFDB
  \item FindStat
  \item Finite groups (Max)
  \item Lattices
  \end{itemize}


  \TODO{deliverable}
\end{task}

\begin{WPDeliverables}
\begin{itemize}
\item Conversion of existing and new databases to unified interoperable system:
  \begin{itemize}
  \item Polytopes in Polymake
  \item graphs, graph properties
  \item LMFDB data
  \item FindStat data
  \item Finite groups (Max)
  \item Lattices
  \end{itemize}
  
\item \ref{del:persistent_memoization} (Month X): Shared persistent
  memoization library for Python/Sage.  Typical use case: A group of
  collaborators is using intensively a given function (in Sage, or in
  their private code). They want to memoize the results, as with
  e.g. Sage's \lstinline{cached_method}, but across sessions.  They
  further want to share the underlying growing database between
  themselves, and maybe eventually publish it.

  Features:
  \begin{itemize}
  \item Use, further extend, and contribute back to some established
    (Python?) persistent memoization infrastructure. E.g.
    \begin{itemize}
    \item \url{https://pythonhosted.org/joblib/memory.html}
    \item \url{github.com/vivekn/redis-simple-cache}
    \item \url{bitbucket.org/zzzeek/dogpile.cache}
    \end{itemize}
  \item Apply not only to user-level functions, but also to lower
    level functions, e.g. in the Sage library, so that indirect calls
    to the function also get memoized.
  \item Trivial to setup and configure for the end user: in a single
    line, the user selects an existing function, a backend (with a
    default value), maybe provide some semantic information, and
    voila. \\
    Typical interface: a decorator to be set on appropriate functions.
    \TODO{Mock code}
    % mycloud = storage("ssh:xxx@yyy/zzz")
    % memoize(sage.combinat...., storage=mycloud, input=ZZ, output=Posets(), key="catalan")
  \item Trivial to setup and configure for groups of researchers, with
    a wide range of storage backends (e.g. shared dropbox folder,
    remote directory, database, git repository, ...).
  \item Easy to setup data-bot: e.g. launching a virtual machine that
    systematically fills up the shared database.
  \item Versioning and provenance tracking (user, algorithm, software
    version, ...), for quality certification, credit, ...
  \item Recomputation?
  \item Ease of publishing, importing, ...
  \item Usual database properties: atomicity, merging (easy since the
    results are supposed to be immutable: just need to merge the
    tracking info), alerts in case of divergence.
  \end{itemize}
\end{itemize}
\end{WPDeliverables}
\begin{verbatim}
Next Generation Math Data/Knowledge/Software-bases.
I would probaly extend the text in the work package with the following
argumentation (replacing the last paragraph)

Mathematics has a richer notion of data than other disciplines.
"Mathematical Data" consists of tree kinds of objects:
[D] : proper (numeric/symbolic) Data
[K] : the knowledge about the mathematical objects given as statements
       (Definitions/Theorems/Proofs; either formal or rigorously informal)
[S] : Software that computes (with) the mathematical objects.
All three kinds of "data" are equally important for mathemathics and and are
tightly interlinked:
- [D] serves as examples for [K] or as counterexamples for Conjectures
in [K]
- [S] computes [D] and establishes properties of [D] (given as [K]),
- [D] tests [S], [S] is verified wrt. [K]
- theorems and proofs in [K] induce and justify algorithms for [S].
- [D] induces conjectures and guides proofs in [K]
Therefore we need ways to represent DKS in the same systems, and - since
DKS
get huge  in current computational/experimental mathematics we need a new
kind of "databases", which we will MDKS-bases (Mathematical Data/Knowledge/
Software-bases).

In the OEIS (which I saw mentioned in the intro, maybe that is
interesting for the proposal) we would have
[D] : the actual sequences (there are 200.000 of them)
[K] : given as formulae, theorems, definitions, and references in the OEIS
       (almost all sequences have them)
[S] : given as Matheamatica/Maple/Gap programs that generate the sequences

I am sure that Paul can give a similar example for the LFMDB.

And then I would conclude like Paul did with "WP6 provides (part of) the
backend for WP4.

Below are four tasks my group could contribute. I would want to work on
them in collaboration with (at least) Paul, with my group being
responsible for the OMDoc/MMT parts and Paul (and others for the LFMDB
and Python/Sage parts. The person months I indicated would be the
contribution necessary from my group.

===================8<---------------------------------


Task K6.3: Triform Theories in OMDoc/MMT (12PM)
D6.3.1: Design of Triform (DKS) Theories (Specification/RNC Schema/Examples)
D6.3.2: Implementation of Triform Theories in the MMT API.
Comments:
  OMDoc/MMT is a representation language for mathematical knowledge and
documents.
  Carette/Farmer have developed the notion of biform theories (K/S) in a
uniform
  representational approach; we have done some work (Paul knows that) on
integrating
  these ideas in OMDoc/MMT. This is what I would like to extend by the
data axis (special,
  but integrated treatment). This is non-trivial theoretical work,
therefore the 12 PM postdoc
  time.

===================8<---------------------------------


Task K6.4: Computational Foundation for Phython/Sage (or some CAS) (12PM)
D6.4.1: Python/Sage Syntax Foundation Module in OMDoc/MMT
D6.4.2: Python/Sage Computational Foundation Module in OMDoc/MMT
D6.4.3: Phtyon/Sage Declarative Semantics in OMDoc/MMT
Comments:
  In the OMDoc/MMT world a foundation is a logical base language that
gives the formal
  meaning to all objects represented/formalized in it. We have created a
very initial
  computational foundation for Scala and implemented it in the MMT API.
This can be used to
  execute (or verify) computations directly in OMDoc/MMT and thus forms
the basis for
  various integration tasks for OMDoc/MMT biform theories that integrate
Scala computations.
  Here we propose to develop a somewhat more complete computational
foundation for Python
  and/or parts of Sage (coverage to be determined). Bi/Triform theories
come in three parts:
  syntax: what operators/types are there, how do they nest, computation:
what does the
  computation relation look like (sometimes called operational
semantics). The declarative
  semantics of a computational foundation can be given as an OMDoc/MMT
theory morphism
  into another foundation (e.g. a set theory); thus the three deliverables.

===================8<---------------------------------


Task K6.5 LDMDB Case study (Triformal Theories) (12 PM)
D6.5.1: LFMDB deep modeling: Fragment Identification & Initial Model Design
D6.5.2: LFMDB Data vs. Knowledge vs. Software Validation
D6.5.3: LFMDB Algorithm verification wrt. a Triformal theory
Comments: In this task we would develop triformal theories for an
exemplary part
  of the LFMDB to test the design from K6.5.  We wil identify a fragment
of the
  LFMDB that we want to model and design the model. Then we will perform
cross-
  validation of the three model parts against each other (essentially
model-based testing
  of software and inference). Finally, we will pick an algorithm from
the LFMDB and verify
  it against its specification and the computational foundation
developed in K6.4.
  This Task will be co-developed with K6.4, it will validate the design
of triformal theories
  and be iterated to test the design changes.

===================8<---------------------------------


Task K6.6. OEIS Case Study (Coverage and automated Import)
D6.6.1: Heuristical Parser for the OEIS
D6.6.2: Cross-Validation for OEIS DKS-Theories.
Comments:
   In this case study we test the practical coverage of the
trifunctional modules, by
   transforming an existing, high-profile database (the Online Sequence
of Integer
   Sequences http://www.oeis.org) into OMDoc/MMT. The OEIS has about 250
thousand
   sequences, with formulae, descriptions, definitions, references,
software, etc. in
   a structured text file (but no standardized format for formulae and
references), so we
   expect to get 250 k theories. Having the OEIS in OMDoc/MMT form
allows to do
   Knowledge Management services (presentation, definition lookup,
formula search, ...)
   in MathHub.info (see WP4.?). The OEIS is a good case study, since the
DKM  are licensed
   under a CC license which allows derived works. The large size will
allow statistically
   significant semantic cross-validation of the heuristic transformation
process and thus
   achieve a significant DKS community resource.

======================8<-----------------------


Another connection: on several occasions, we found that software was
the best way to represent certain databases of mathematical
knowledge. E.g. in Algebraic Combinatorics we have a whole zoo of Hopf
algebras. Many of them are implemented in MuPAD/Sage by specifying the
objects that index the basis together with computation rules for the
product and coproduct. When we want to retrieve information about such
algebras, it's usually much more convenient to look at the code than
to search through the literature. Especially since the code is usually
more correct than the literature because it's *tested*.



We may also think of providing an interface to LMFDB via SCSCP
protocol (http://www.symbolic-computing.org/scscp) so it may
be accessed by a variety of other systems (see their current
list at http://www.symbolic-computing.org/scscp)


database access to LMFDB as a python library


\end{verbatim}
\end{Workpackage}
