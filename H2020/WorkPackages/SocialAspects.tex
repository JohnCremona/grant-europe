\begin{draft}
\TOWRITE{DP (Work Package Lead)}{For WP leaders, please check the following (remove items
once completed)}
\begin{verbatim}
- [ ] have all the tasks in this Work Package a lead institution?
- [ ] have all deliverables in the WP a lead institution?
- [ ] do all tasks list all sites involved in them? 
- [ ] does the table of sites and their PM efforts match lists of sites for each task?
      (each site from the table is listed in all relevant tasks, and no site is listed
      only in the table or only at some task)
\end{verbatim}
\end{draft}



\begin{workpackage}[id=social-aspects,wphases=0-48,
  title=Social Aspects,
  lead=UO,
  UORM=27,USHRM=8, USORM=6]

%\TOWRITE{DP/UM}{workpackage Social Aspects}
% At Nicolas' request I'm having a go so there is something here
% SL

\begin{wpobjectives}

The processes by which mathematical knowledge and mathematical
software are developed, validated and applied are quite
distinctive. In other sciences, the universe provides ``ground truth''
and the scientific texts or theories can be validated against that by
experiment. In mathematics the text is the ground truth. Once a
mathematician, or a small group of mathematicians standing around a
blackboard, produced a proof they would ``clean it up'' removing all
traces of the process by which it had been discovered and then submit
the ``clean'' text to their peers for review.

Mathematicians have adopted new technology is a range of ways: email
and shared documents are used to collaborate on problem-solving and
writing; larger ``crowdsourcing'' \cite{polymath_SIAM, PolymathBlog},
arrangements pull together diverse experts; symbolic computation
tackles huge routine calculations; and computers check proofs that are
just too long and complicated for any human to comprehend. This
technology is both revealing (since email messages, version control
systems and bulletin boards can be analyzed) and altering the ways in
which mathematicians collaborate.

In an EPSRC funded project ``The Social Machine of Mathematics''
Martin and others are bringing rigorous methods from the social 
sciences together to study these processes. This brings up the following
objectives: 
\begin{compactitem}
\item to bring the insights of this and similar projects into the
  design of \TheProject VRE, ensuring that it supports the ways in
  which mathematicians really work, and not just the way software
  developers or indeed mathematicians, think they do;
\item to extend this work to study the collaborative processes of
  free open source
  (mathematical) software development to produce guidelines for best
  practice and ideas for how existing processes can extend to a
  ``system of systems''.
%\item  \TODO{Possibly a recomputation-style objective as well --
%  encouraging people to do computational research in a better way}
\end{compactitem} 

%  \TODO{Neil: I've provided some text below on repeatability on
%    exchange of ideas. I don't want to edit too much into the
%    mechanism design section, but I feel that both things are needed
%    here to entice users into the ecosystem. I.e. a good mechanism is
%    useless if no-one is interested in the underlying
%    product/phenomenom. Can these two concepts be combined? I think
%    that would strengthen this WP.}

Social aspects of interactions are at a focus of attention
of a burgeoning field of \emph{algorithmic game theory} and 
in particular \emph{mechanism design} \cite{AGTbook}, which provide \emph{tools} to engineer 
environments where all participants are incentivised to contribute to the common good.
This brings up the following objectives:
\begin{compactitem}
\item as we are concerned with the ``mutual
crowdsourcing'' phenomenon occurring in modern scientific collaboration, and in particular 
in the framework of development and maintenance of an open-source VRE,   
we can draw upon recent research on crowdsourcing in algorithmic
mechanism design \cite{crowds}.
We will focus on identifying the incentives for all participants of the
system, encouraging sustained development of the most
important parts;
\item while doing so, we will apply outcomes to a case study system---\TheProject\ VRE;  
\item cohesiveness of comminities of developers and users of open source softaware, and
VREs in particular, is a matter of concern, as disagreements often tend to lead to
forks (i.e. splitting of the software ecosystem into two or more competing one) and
other developer/user losses. Tools from
cooperative game theory  should provide rigorous mechanisms to mitigate these
issues as much as possible. 
\end{compactitem}

%% From Neil (on the repeatability front if this is thought to be a good idea. Not integrated with the below though. Mechanism design is good, 
VREs have steep learning curves, and users need to be enticed into
their ecosystems. To this end, we will look into the
questions of understanding of and trust in results produced by computations done by VREs,
and ways to mitigate the issues arising there. More specifically,
mathematics provides a common language amongst the quantitative
sciences, however presentations of mathematics, and mathematical
models, are not always consummate with clear propagation of ideas that
the mathematics encode. By closely intertwining the application with
the mathematics, the project will develop more widespread
understanding of the utility of a mathematical abstraction and
encourage repeatability of analysis. \TheProject should enable
user-friendly presentation of the abstraction to such an extent that
even non computational/mathematical scientists feel compelled to
interact with and explore the model.
\end{wpobjectives}

\begin{wpdescription}
Crowdsourcing is a recent phenomenon in software development in
particular, but not only there. E.g.  crowdsourcing of mathematical
ideas occurs in online mathematics communities, such as Math-overflow
\cite{mathoverflow} and in Polymath Projects \cite{polymath_SIAM, PolymathBlog}.
``Mutual crowdsourcing'' is the main driving force in developing and
maintaining of any large-scale open-source virtual research
environment.

Open source projects tend to be fragile, in the community sense, and
suffer from disagreements that ultimately result in forks and the
resulting repetition of effort. We will analyse this in a setup of
cooperative game theory, and try to design a finely tuned systems of
incentives and rewards for contribution, to increase the stability of
the community and its useful output.

We will focus on identifying the appropriate incentives for all
participants of the system, that would encourage sustained development
of the most important parts of the system.  To this end, we will use
ideas from the burgeoning field of mechanism design \cite{AGTbook} and
in particular on recent research on crowdsourcing in algorithmic
mechanism design \cite{crowds}.  While doing so, we will apply
outcomes to a case study system --- \Sage.  We will apply preference
and opinion aggregation techniques \cite{pref-aggr} to develop a
community prioritisation scheme for \Sage bugs and features requests,
which are presently being maintained on the \Sage TRAC server
\cite{trac-sagemath} and implement them as a TRAC \cite{Trac} add-on.

As well, we will study various development models for an academic free
software ecosystem, and analyse how they facilitate the mathematical
process behind algorithms being designed and implemented, and
databases of experimental data and test cases being created and
expanded.  Trusting results of computer computations is crucial for
usability; channels for communicating bug reports and fixes need to be
carefully analysed from social point of view.  Commercial closed
source computer algebra and other computational systems often fail to
react to bug reports in a timely manner, and seemingly are falling
into the short-sighted trap of hiding bugs from potential and current
users \cite{misfort}, Open source systems are only marginally better
in this way, as recent computer security scares, such as the one
around Bash \cite{shellshock}, indicate.  A game-theoretic analysis of
this situation will be attempted.
\end{wpdescription}

\begin{tasklist}
\begin{task}[title=Modern Distribution of Scientific Output]
  \TODO{Neil: a suggested task in this domain, it's an area I've been
    thinking about a lot and it could fit in here. } The current model
  for distribution of scientific output stems from an era when the
  printing press was dominant. The process has become formalized
  through peer review and publication of journals. The PDF format for
  distribution of documents reflects the status quo, that a scientific
  paper is a written as if for printing and remains an unchanging
  document. In scientific blogging we are seeing that more rapid
  propagation of ideas can occur when the constrains of the printed
  format are released, however, there is a lack of formalization that
  means attribution of ideas and commentary run amiss. We will develop
  tools and ideas for distribution of scientific knowledge that don't
  rely on a static format and allow for the full spectrum of
  scientific debate. The tools will encourage proper credit
  attribution through encouraging sharing of attribution for ideas,
  software and data. We will develop live posters for distribution of
  knowledge, designed for integration with either large touch screens
  or smaller tablets \localdelivref{social-poster}. We will augment
  the Jupyter project with facilities for providing comment on
  notebooks to encourage debate on mathematical and computational
  ideas \localdelivref{jupyter-comment}.
\end{task}

\begin{task}[title=Survey and collection of needed data,id=datacollection]
We will survey the data needed to assess development models of
large-scale academic open-source projects, such that the probable
correlation between the size of the atomic contribution vs. the speed
of the contribution making it into the code, and collect appropriate
statistical data. The latter will require non-trivial amount of
programming work, even only for the test system, \Sage.
\end{task}

\begin{task}[title=Collective decision making in development,id=decisionmaking]
Currently development of open-source academic software is task-driven,
where tasks (also known as tickets) are posted on a website, and their
priorities are set in an ad hoc manner.  Whereas the latter might be
good enough for simple bug fixing, for more elaborate task this often
leads to delays etc.  We would like to investigate an voting-driven
approach, where the priorities are being voted on by the developer
community, and possibly the people who completed tasks are
incentivised in some form (e.g. by ``karma points'', as on
MathOverflow).
\end{task}

\begin{task}[title=Evaluation of Micromagnetic VRE,lead=USO,PM=6,
id=oommf-nb-evaluation,partners={UO,PS}]
  % 4 person months, 1 person month investigator time
  We will use the micromagnetic VRE demonstrator
  (\taskref{UI}{oommf-tutorial-and-documentation}), its dissemination
  workshops \linebreak(\taskref{dissem}{dissemination-of-oommf-nb-workshops})
  and interactions with its users and contributors in the
  micromagnetic community to evaluate, reflect and report on the project,
  taking into account technical and social aspects.

  A survey will be developed and used to gather user input and
  feedback on usefulness of the provided capabilities, with particular
  focus on the capabilities of the micromagnetic VRE to (i) enable new
  and better science, to (ii) allow to make progress effectively, to
  (iii) carry out computational science reproducibly, to (iv)
  collaboratively enable trust and to (v) become a self-sustained
  project from community contributions. Amongst other channels, we
  will target attendees of the micromagnetic VRE dissemination
  workshops (\taskref{dissem}{dissemination-of-oommf-nb-workshops}) to
  gather data.

  All results and insights will be summarised in a public document
  (\localdelivref{oommf-nb-evaluation}) and reported at appropriate
  workshops and conferences to share the lessons learned from this
  \Jupyter-based VRE for micromagnetics. We will create a manuscript
  for journal publication, summarising the demonstrator project and
  this evaluation. An important point of this publication is to
  provide a reference that can be cited by publications making use of
  the new micromagnetic VRE, to allow tracking of uptake and
  development of this VRE beyond the life time of this H2020 project.
\end{task}



\end{tasklist}

% Things to investigate?
% - User surveys. Cf. https://groups.google.com/d/msg/sage-devel/v8Kfky4p6D4/_xRM0bggCo8J
% - The discussion about Code of Conducts and the like

\begin{wpdelivs}
%   \begin{wpdeliv}[due=12,id=social-...,dissem=PU,nature=??]
%       {...}
% \end{wpdeliv}
 \begin{wpdeliv}[due=36,id=social-poster,dissem=PU,nature=DEM,lead=USH]
   {Demonstrator: Jupyter Notebook Live Poster} 
\end{wpdeliv}
 \begin{wpdeliv}[due=24,id=social-poster,dissem=PU,nature=DEM,lead=USH]
   {Demonstrator: Mechanism for comment on posted Jupyter notebooks.} 
\end{wpdeliv}
 \begin{wpdeliv}[due=48,id=oommf-nb-evaluation,dissem=PU,nature=R,lead=USO]
      {Micromagnetic VRE environment evaluation report}
\end{wpdeliv}
\end{wpdelivs}
\end{workpackage}
%%% Local Variables:
%%% mode: latex
%%% TeX-master: "../proposal"
%%% End:

%  LocalWords:  workpackage wphases TOWRITE wpobjectives analyse wpdescription AGTbook
%  LocalWords:  mathoverflow Sagemath pref-aggr prioritisation trac-sagemath Trac misfort
%  LocalWords:  analysed shellshock tasklist datacollection decisionmaking incentivised
%  LocalWords:  OOMMFNB taskref oommf-python-interface oommf-tutorial-and-documentation
%  LocalWords:  micromagnetic dissem dissemination-of-oommf-nb-virtual-environment texttt
%  LocalWords:  dissemination-of-oommf-nb-workshops summarised delivref wpdelivs wpdeliv
%  LocalWords:  oommf-nb-evaluation compactitem recomputation-style phenomenom
%  LocalWords:  localdelivref
